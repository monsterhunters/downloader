{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monsterhunters/downloader/blob/main/downloaderV8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gdrive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3WCj-Iz-zEGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AWVmDGr0Nme4"
      },
      "outputs": [],
      "source": [
        "#@title <img src=\"https://rapidgator.net/images/logo.png\" width=\"120px\" >\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/javsubs91/RAPIDGATOR-COLAB-DOWNLOADER/main/rgcolab.py &> /dev/null\n",
        "#!mkdir /content/downloads\n",
        "import os, sys, re\n",
        "RAPIDGATOR_EMAIL = '' #@param {type:\"string\"}\n",
        "RAPIDGATOR_PASSWORD = '' #@param {type:\"string\"}\n",
        "RAPIDGATOR_LINK = '' #@param {type:\"string\"}\n",
        "output_path = \"\" # @param {type:\"string\"}\n",
        "!python rgcolab.py \"$RAPIDGATOR_EMAIL\" \"$RAPIDGATOR_PASSWORD\" \"$RAPIDGATOR_LINK\" $output_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <img src=\"https://nitroflare.com/img/logo_en.png\" width=\"120px\"> <br>\n",
        "import os, re, requests\n",
        "\n",
        "single_line_batch_links = \"\" # @param {type:\"string\"}\n",
        "\n",
        "perlink = single_line_batch_links.split(\" \")\n",
        "\n",
        "if single_line_batch_links != \"\" :\n",
        "\n",
        "    files = perlink\n",
        " #   print(files)\n",
        "\n",
        "else:\n",
        "\n",
        "    file_url1 = \"\" # @param {type:\"string\"}\n",
        "    file_url2 = \"\" # @param {type:\"string\"}\n",
        "    file_url3 = \"\" # @param {type:\"string\"}\n",
        "    file_url4 = \"\" # @param {type:\"string\"}\n",
        "    file_url5 = \"\" # @param {type:\"string\"}\n",
        "\n",
        "    files = [file_url1, file_url2, file_url3, file_url4, file_url5]\n",
        "\n",
        "server = \"server2\" # @param [\"server1\", \"server2\", \"server3\", \"server4\", \"server5\", \"server6\", \"server7\", \"server8\", \"server9\"]\n",
        "output_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "if server == \"server1\":\n",
        "    username = \"totalleecher@gmail.com\"\n",
        "elif server == \"server2\":\n",
        "    username = \"kyawkaung709@gmail.com\"\n",
        "elif server == \"server3\":\n",
        "    username = \"bssgserverx@gmail.com\"\n",
        "elif server == \"server4\":\n",
        "    username = \"sdserver1@gmail.com\"\n",
        "elif server == \"server5\":\n",
        "    username = \"sdserver2@gmail.com\"\n",
        "elif server == \"server6\":\n",
        "    username = \"lohohig392@fgvod.com\"\n",
        "elif server == \"server7\":\n",
        "    username = \"uebwfca950@tmail3.com\"\n",
        "elif server == \"server8\":\n",
        "    username = \"niwel37892@fgvod.co\"\n",
        "else:\n",
        "    username = \"luriqado@decabg.eu\"\n",
        "\n",
        "for file_url in files:\n",
        "  if file_url == \"\":\n",
        "    continue\n",
        "  else:\n",
        "    # Extract the file code from the URL\n",
        "    parts = file_url.split('/')\n",
        "    filecode = parts[-2] if len(parts) >= 2 else None\n",
        " #   print(filecode)\n",
        "    if filecode:\n",
        "        # Construct the download link URL\n",
        "        url = f\"https://nitroflare.com/api/v2/getDownloadLink?user={username}&premiumKey=12345678&file={filecode}\"\n",
        "        # Send a GET request to fetch the download link\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            json_data = response.json()\n",
        "            download_url = json_data.get('result', {}).get('url')\n",
        "      #      print(download_url)\n",
        "            if download_url:\n",
        "                # Use wget to download the file to the specified output_path\n",
        "                !wget -P $output_path $download_url\n",
        "            else:\n",
        "                print(\"Failed to fetch download URL from Nitroflare API.\")\n",
        "        else:\n",
        "            print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
        "    else:\n",
        "        print(\"Failed to extract file code from the URL.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2KfzwwhIdPUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <img src=\"https://assets.katfile.com/images/logo.png\" width=\"100px\">\n",
        "\n",
        "import os, re, requests\n",
        "\n",
        "single_line_batch_links = \"\" # @param {type:\"string\"}\n",
        "\n",
        "perlink = single_line_batch_links.split(\" \")\n",
        "\n",
        "if single_line_batch_links != \"\" :\n",
        "\n",
        "    files = perlink\n",
        "\n",
        "else:\n",
        "\n",
        "    file_url1 = \"\" # @param {type:\"string\"}\n",
        "    file_url2 = \"\" # @param {type:\"string\"}\n",
        "    file_url3 = \"\" # @param {type:\"string\"}\n",
        "    file_url4 = \"\" # @param {type:\"string\"}\n",
        "    file_url5 = \"\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "    files = [file_url1, file_url2, file_url3, file_url4, file_url5]\n",
        "\n",
        "\n",
        "for url in files:\n",
        "  if url == \"\":\n",
        "    continue\n",
        "  else:\n",
        "    output_path = \"\" # @param {type:\"string\"}\n",
        "    apiKey = \"699996yph6h88a7rc6c1g8\"\n",
        "    parts = url.split('/')\n",
        "    domain = parts[2]\n",
        "    filecode = parts[3]\n",
        "  #  print(parts)\n",
        "  #  print(domain)\n",
        "  #  print(filecode)\n",
        "    #https://katfile.com/api/file/clone?key=699996yph6h88a7rc6c1g8&file_code=zrzac82zifv0\n",
        "    cloneurl = f\"https://{domain}/api/file/clone?key={apiKey}&file_code={filecode}\"\n",
        "    response = requests.get(cloneurl)\n",
        "    if response.status_code == 200:\n",
        "        json_data = response.json()\n",
        "        download_url = json_data.get('result', {}).get('url')\n",
        "    #    print(download_url)\n",
        "        parts_final = download_url.split('/')\n",
        "        filecodex = parts_final[3]\n",
        "        final_url= f\"https://{domain}/api/file/direct_link?key={apiKey}&file_code={filecodex}\"\n",
        "        response = requests.get(final_url)\n",
        "        if response.status_code == 200:\n",
        "            json_data = response.json()\n",
        "            download_url = json_data.get('result', {}).get('url')\n",
        "         #   print(download_url)\n",
        "            !wget -P $output_path $download_url\n",
        "        else:\n",
        "            print(\"Error while fetching Katfile API\")\n",
        "    else:\n",
        "      print(\"Error while fetching Katfile API\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z4ALuK-YqlQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <img src=\"data:image/png;base64,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\" width=\"150px\">\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "from sys import argv\n",
        "from bs4 import BeautifulSoup\n",
        "from humanize import naturalsize\n",
        "from urllib.parse import quote, unquote\n",
        "import subprocess\n",
        "import pathlib\n",
        "import shutil\n",
        "import hashlib\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from os import path, mkdir\n",
        "\n",
        "# --Youtube DL--\n",
        "!pip show youtube-dl --quiet || pip install youtube-dl --quiet\n",
        "#--END\n",
        "\n",
        "\n",
        "\n",
        "single_line_batch_links = \"\"  # @param {type:\"string\"}\n",
        "OUTPUT_PATH = \"\"  # @param {type:\"string\"}\n",
        "split = 16 # @param {type:\"slider\", min:1, max:16, step:1}\n",
        "connection = 15 # @param {type:\"slider\", min:1, max:16, step:1}\n",
        "\n",
        "perlink = single_line_batch_links.split(\" \")\n",
        "\n",
        "if single_line_batch_links != \"\":\n",
        "\n",
        "    files = perlink\n",
        "\n",
        "    for terabox_url in files:\n",
        "        if terabox_url == \"\":\n",
        "            continue\n",
        "        else:\n",
        "\n",
        "            # sample_url = \"https://teraboxapp.com/s/13FlMJT4cytJbA00IBUWX0w\" # file with directories\n",
        "            # sample_url = \"https://terabox.app/s/16oyv6pH-e97aYGPrLpbTTQ\" # only file\n",
        "\n",
        "            json_data_url = \"https://www.terabox.com/share/list?jsToken={jsToken}&shorturl={key}\"\n",
        "            cookies = {\"ndus\": \"YbDgQCEteHui0Bx8sPAmBS3hSB4K79edBrj6PrJq\"}\n",
        "            jsToken = None\n",
        "            key = None\n",
        "\n",
        "            def process_terabox(terabox_url):\n",
        "                global jsToken, key, cookies\n",
        "                req = requests.get(terabox_url, cookies=cookies)\n",
        "                soup = BeautifulSoup(req.content, \"html.parser\")\n",
        "                result = soup.find_all(\"script\")[3]\n",
        "                if match := re.search(r'\"([^\"]+)\"', unquote(result.text)):\n",
        "                    jsToken = match.group(1)\n",
        "                key = req.url.split(\"=\")[1]\n",
        "\n",
        "            def bypass_directory_logic(jsToken, key, link, cookies, depth=0):\n",
        "                if depth >= 10:\n",
        "                    return\n",
        "\n",
        "                res = requests.get(link, cookies=cookies)\n",
        "                data = res.json()\n",
        "                if \"list\" in data:\n",
        "                    for item in data[\"list\"]:\n",
        "                        if \"dlink\" in item:\n",
        "                            path = item['path'].rsplit(\"/\", 1)\n",
        "                            title = item['server_filename']\n",
        "                            size = item['size']\n",
        "                            dlink = item['dlink']\n",
        "\n",
        "                            print(f\"Path: {path[0]}\")\n",
        "                            print(f\"Title: {title}\")\n",
        "                            print(f\"Size: {naturalsize(size)}\")\n",
        "                            print(f\"Dlink: {dlink}\\n\")\n",
        "\n",
        "                        if \"path\" in item:\n",
        "                            _path = quote(item[\"path\"]).replace(\"/\", \"%2F\")\n",
        "                            sub_link = f\"{json_data_url.format(jsToken=jsToken, key=key)}&dir={_path}\"\n",
        "                            bypass_directory_logic(jsToken, key, sub_link, cookies, depth + 1)\n",
        "\n",
        "            process_terabox(terabox_url)\n",
        "\n",
        "            base = json_data_url.format(jsToken=jsToken, key=key)\n",
        "            res = requests.get(f\"{base}&root=1\", cookies=cookies)\n",
        "            try:\n",
        "                meta = res.json()[\"list\"][0]\n",
        "                title = meta['server_filename']\n",
        "                size = meta['size']\n",
        "                dlink = meta['dlink']\n",
        "\n",
        "                print(f\"Title: {title}\")\n",
        "                print(f\"Size: {naturalsize(size)}\")\n",
        "                print(f\"Dlink: {dlink}\")\n",
        "            except KeyError:\n",
        "                _path = quote(res.json()[\"list\"][0][\"path\"]).replace(\"/\", \"%2F\")\n",
        "                link = f'{json_data_url.format(jsToken=jsToken, key=key)}&dir={_path}'\n",
        "                bypass_directory_logic(jsToken, key, link, cookies)\n",
        "\n",
        "            URL = dlink\n",
        "\n",
        "\n",
        "            if not path.exists(\"/root/.ipython/ttmg.py\"):\n",
        "                from subprocess import run\n",
        "                from shlex import split\n",
        "\n",
        "                shellCmd = \"wget -qq https://raw.githubusercontent.com/totalleecher/\" \\\n",
        "                            \"Google-Colab-CloudTorrent/master/res/ttmg.py \\\n",
        "                                -O /root/.ipython/ttmg.py\"\n",
        "                run(split(shellCmd))\n",
        "            from ttmg import updateCheck, runSh\n",
        "\n",
        "            def youtubedlInstall():\n",
        "              if not path.isfile(\"/usr/local/bin/youtube-dl\"):\n",
        "                cmdC = \"rm -rf /content/sample_data/ && \" \\\n",
        "                        \" mkdir -p -m 666 /root/.YouTube-DL/ &&\" \\\n",
        "                        \" apt-get install atomicparsley &&\" \\\n",
        "                        \" curl -L https://yt-dl.org/downloads/latest/youtube-dl \" \\\n",
        "                        \"-o /usr/local/bin/youtube-dl &&\" \\\n",
        "                        \" chmod a+rx /usr/local/bin/youtube-dl\"\n",
        "                get_ipython().system_raw(cmdC)\n",
        "\n",
        "            def aria2Install():\n",
        "              runSh('apt install -y aria2')\n",
        "\n",
        "            def istmd(URL):\n",
        "              link = urlparse(URL)\n",
        "\n",
        "              #YandexDisk\n",
        "              if link.netloc == \"yadi.sk\":\n",
        "                API_ENDPOINT = 'https://cloud-api.yandex.net/v1/disk/public/resources/' \\\n",
        "                                '?public_key={}&path=/{}&offset={}'\n",
        "                dry = False\n",
        "                def md5sum(file_path):\n",
        "                    md5 = hashlib.md5()\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        for chunk in iter(lambda: f.read(128 * md5.block_size), b''):\n",
        "                            md5.update(chunk)\n",
        "                    return md5.hexdigest()\n",
        "\n",
        "\n",
        "                def check_and_download_file(target_path, url, size, checksum):\n",
        "                    if path.isfile(target_path):\n",
        "                        if size == path.getsize(target_path):\n",
        "                            if checksum == md5sum(target_path):\n",
        "                                print('URL {}'.format(url))\n",
        "                                print('skipping correct {}'.format(target_path))\n",
        "                                return\n",
        "                    if not dry:\n",
        "                        print('URL {}'.format(url))\n",
        "                        print('downloading {}'.format(target_path))\n",
        "                        runSh(f'aria2c -x 16 -s 16 -k 1M -d {OUTPUT_PATH} {url}', output=True)\n",
        "                        # r = requests.get(url, stream=True)\n",
        "                        # with open(target_path, 'wb') as f:\n",
        "                        #     shutil.copyfileobj(r.raw, f)\n",
        "\n",
        "\n",
        "                def download_path(target_path, public_key, source_path, offset=0):\n",
        "                    print('getting \"{}\" at offset {}'.format(source_path, offset))\n",
        "                    current_path = path.join(target_path, source_path)\n",
        "                    pathlib.Path(current_path).mkdir(parents=True, exist_ok=True)\n",
        "                    jsn = requests.get(API_ENDPOINT.format(public_key, source_path, offset)).json()\n",
        "                    def try_as_file(j):\n",
        "                        if 'file' in j:\n",
        "                            file_save_path = path.join(current_path, j['name'])\n",
        "                            check_and_download_file(file_save_path, j['file'], j['size'], j['md5'])\n",
        "                            return True\n",
        "                        return False\n",
        "\n",
        "                    # first try to treat the actual json as a single file description\n",
        "                    if try_as_file(jsn):\n",
        "                        return\n",
        "\n",
        "                    # otherwise treat it as a directory\n",
        "                    emb = jsn['_embedded']\n",
        "                    items = emb['items']\n",
        "                    for i in items:\n",
        "                        # each item can be a file...\n",
        "                        if try_as_file(i):\n",
        "                            continue\n",
        "                        # ... or a directory\n",
        "                        else:\n",
        "                            subdir_path = path.join(source_path, i['name'])\n",
        "                            download_path(target_path, public_key, subdir_path)\n",
        "\n",
        "                    # check if current directory has more items\n",
        "                    last = offset + emb['limit']\n",
        "                    if last < emb['total']:\n",
        "                        download_path(target_path, public_key, source_path, last)\n",
        "                download_path(OUTPUT_PATH, URL, '')\n",
        "                return False\n",
        "              return URL\n",
        "\n",
        "            if not OUTPUT_PATH:\n",
        "              OUTPUT_PATH = \"/content/drive/My Drive/DirectDownload\"\n",
        "\n",
        "            if not URL == \"\":\n",
        "              aria2Install()\n",
        "              youtubedlInstall()\n",
        "              try:\n",
        "                mkdir(\"DirectDownload\")\n",
        "              except FileExistsError:\n",
        "                pass\n",
        "              url = istmd(URL)\n",
        "              if url != False:\n",
        "                print('URL {}'.format(URL))\n",
        "                cmdC = f'youtube-dl -o \"{OUTPUT_PATH}/{title}\" {URL} ' \\\n",
        "                       f'--external-downloader aria2c ' \\\n",
        "                       f'--external-downloader-args \"-x {str(connection)} -s {str(split)}\"'\n",
        "                runSh(cmdC, output=True)\n",
        "            else:\n",
        "              print(\"Please input url\")\n",
        "\n",
        "else:\n",
        "    print('Enter Terabox Url')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bwF-1ZYC8E8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plgToqkpLV5q",
        "cellView": "form"
      },
      "source": [
        "# @title <h3><b>←</b> Direct Downloader\n",
        "\n",
        "%cd /content/drive/My Drive\n",
        "%mkdir DirectDownload\n",
        "\n",
        "#\n",
        "# --Youtube DL--\n",
        "!pip show youtube-dl --quiet || pip install youtube-dl --quiet\n",
        "#--END\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "URL = \"\" #@param {type:\"string\"}\n",
        "OUTPUT_PATH = \"\" #@param {type:\"string\"}\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import hashlib\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from os import path, mkdir\n",
        "if not path.exists(\"/root/.ipython/ttmg.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/totalleecher/\" \\\n",
        "                \"Google-Colab-CloudTorrent/master/res/ttmg.py \\\n",
        "                    -O /root/.ipython/ttmg.py\"\n",
        "    run(split(shellCmd))\n",
        "from ttmg import updateCheck, runSh\n",
        "\n",
        "def youtubedlInstall():\n",
        "  if not path.isfile(\"/usr/local/bin/youtube-dl\"):\n",
        "    cmdC = \"rm -rf /content/sample_data/ && \" \\\n",
        "            \" mkdir -p -m 666 /root/.YouTube-DL/ &&\" \\\n",
        "            \" apt-get install atomicparsley &&\" \\\n",
        "            \" curl -L https://yt-dl.org/downloads/latest/youtube-dl \" \\\n",
        "            \"-o /usr/local/bin/youtube-dl &&\" \\\n",
        "            \" chmod a+rx /usr/local/bin/youtube-dl\"\n",
        "    get_ipython().system_raw(cmdC)\n",
        "\n",
        "def aria2Install():\n",
        "  runSh('apt install -y aria2')\n",
        "\n",
        "def istmd(URL):\n",
        "  link = urlparse(URL)\n",
        "\n",
        "  #YandexDisk\n",
        "  if link.netloc == \"yadi.sk\":\n",
        "    API_ENDPOINT = 'https://cloud-api.yandex.net/v1/disk/public/resources/' \\\n",
        "                    '?public_key={}&path=/{}&offset={}'\n",
        "    dry = False\n",
        "    def md5sum(file_path):\n",
        "        md5 = hashlib.md5()\n",
        "        with open(file_path, 'rb') as f:\n",
        "            for chunk in iter(lambda: f.read(128 * md5.block_size), b''):\n",
        "                md5.update(chunk)\n",
        "        return md5.hexdigest()\n",
        "\n",
        "\n",
        "    def check_and_download_file(target_path, url, size, checksum):\n",
        "        if path.isfile(target_path):\n",
        "            if size == path.getsize(target_path):\n",
        "                if checksum == md5sum(target_path):\n",
        "                    print('URL {}'.format(url))\n",
        "                    print('skipping correct {}'.format(target_path))\n",
        "                    return\n",
        "        if not dry:\n",
        "            print('URL {}'.format(url))\n",
        "            print('downloading {}'.format(target_path))\n",
        "            runSh(f'aria2c -x 16 -s 16 -k 1M -d {OUTPUT_PATH} {url}', output=True)\n",
        "            # r = requests.get(url, stream=True)\n",
        "            # with open(target_path, 'wb') as f:\n",
        "            #     shutil.copyfileobj(r.raw, f)\n",
        "\n",
        "\n",
        "    def download_path(target_path, public_key, source_path, offset=0):\n",
        "        print('getting \"{}\" at offset {}'.format(source_path, offset))\n",
        "        current_path = path.join(target_path, source_path)\n",
        "        pathlib.Path(current_path).mkdir(parents=True, exist_ok=True)\n",
        "        jsn = requests.get(API_ENDPOINT.format(public_key, source_path, offset)).json()\n",
        "        def try_as_file(j):\n",
        "            if 'file' in j:\n",
        "                file_save_path = path.join(current_path, j['name'])\n",
        "                check_and_download_file(file_save_path, j['file'], j['size'], j['md5'])\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "        # first try to treat the actual json as a single file description\n",
        "        if try_as_file(jsn):\n",
        "            return\n",
        "\n",
        "        # otherwise treat it as a directory\n",
        "        emb = jsn['_embedded']\n",
        "        items = emb['items']\n",
        "        for i in items:\n",
        "            # each item can be a file...\n",
        "            if try_as_file(i):\n",
        "                continue\n",
        "            # ... or a directory\n",
        "            else:\n",
        "                subdir_path = path.join(source_path, i['name'])\n",
        "                download_path(target_path, public_key, subdir_path)\n",
        "\n",
        "        # check if current directory has more items\n",
        "        last = offset + emb['limit']\n",
        "        if last < emb['total']:\n",
        "            download_path(target_path, public_key, source_path, last)\n",
        "    download_path(OUTPUT_PATH, URL, '')\n",
        "    return False\n",
        "  return URL\n",
        "\n",
        "if not OUTPUT_PATH:\n",
        "  OUTPUT_PATH = \"/content/drive/My Drive/DirectDownload\"\n",
        "\n",
        "if not URL == \"\":\n",
        "  aria2Install()\n",
        "  youtubedlInstall()\n",
        "  try:\n",
        "    mkdir(\"DirectDownload\")\n",
        "  except FileExistsError:\n",
        "    pass\n",
        "  url = istmd(URL)\n",
        "  if url != False:\n",
        "    print('URL {}'.format(URL))\n",
        "    cmdC = f'youtube-dl -o \"{OUTPUT_PATH}/%(title)s.%(ext)s\" {URL} ' \\\n",
        "           '--external-downloader aria2c ' \\\n",
        "           '--external-downloader-args \"-x 16 -s 16 -k 1M\"'\n",
        "    runSh(cmdC, output=True)\n",
        "else:\n",
        "  print(\"Please input url\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "import threading\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from ipywidgets import Button, Output\n",
        "from ipywidgets import FileUpload, VBox, HBox\n",
        "from IPython.display import display\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import hashlib\n",
        "from urllib.parse import urlparse\n",
        "from os import path, mkdir\n",
        "if not path.exists(\"/root/.ipython/ttmg.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/totalleecher/\" \\\n",
        "                \"Google-Colab-CloudTorrent/master/res/ttmg.py \\\n",
        "                    -O /root/.ipython/ttmg.py\"\n",
        "    run(split(shellCmd))\n",
        "from ttmg import updateCheck, runSh\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --Youtube DL--\n",
        "!pip show youtube-dl --quiet || pip install youtube-dl --quiet\n",
        "#--END\n",
        "\n",
        "# @title <h3><b>←</b> Batch Download from txt file\n",
        "\n",
        "OUTPUT_PATH =  \"\" # @param {type:\"string\"}\n",
        "\n",
        "def main():\n",
        "    global upload_button\n",
        "    upload_button = FileUpload(accept='.txt', multiple=False)\n",
        "    global upload_output\n",
        "    upload_output = VBox([upload_button])\n",
        "    print('Upload a text file containing the URLs to download:')\n",
        "    display(upload_output)\n",
        "    upload_button.observe(on_upload_button_click, names='value')\n",
        "\n",
        "\n",
        "def on_upload_button_click(change):\n",
        "    global urls\n",
        "    global download_button\n",
        "    global progress_output\n",
        "    file_name = list(upload_button.value.keys())[0]\n",
        "    file_content = upload_button.value[file_name]['content']\n",
        "    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', file_content.decode('utf-8'))\n",
        "    download_button = Button(description='Start Download')\n",
        "    download_button.on_click(on_download_button_click)\n",
        "    progress_output = VBox([])\n",
        "    upload_output.children = [VBox([download_button, progress_output])]\n",
        "\n",
        "\n",
        "def youtubedlInstall():\n",
        "    if not path.isfile(\"/usr/local/bin/youtube-dl\"):\n",
        "        cmdC = \"rm -rf /content/sample_data/ && \" \\\n",
        "               \" mkdir -p -m 666 /root/.YouTube-DL/ &&\" \\\n",
        "               \" apt-get install atomicparsley &&\" \\\n",
        "               \" curl -L https://yt-dl.org/downloads/latest/youtube-dl \" \\\n",
        "               \"-o /usr/local/bin/youtube-dl &&\" \\\n",
        "               \" chmod a+rx /usr/local/bin/youtube-dl\"\n",
        "        os.system(cmdC)\n",
        "\n",
        "\n",
        "def aria2Install():\n",
        "    os.system('apt install -y aria2')\n",
        "\n",
        "\n",
        "def on_download_button_click(change):\n",
        "    global OUTPUT_PATH\n",
        "    global urls\n",
        "    global progress_output\n",
        "\n",
        "    OUTPUT_PATH = OUTPUT_PATH or \"/content/drive/My Drive/DirectDownload\"\n",
        "\n",
        "    progress_output.children = [Button(description='Downloading...', disabled=True)]\n",
        "\n",
        "    for url in urls:\n",
        "      if urls != \"\":\n",
        "          aria2Install()\n",
        "          youtubedlInstall()\n",
        "          try:\n",
        "              mkdir(\"DirectDownload\")\n",
        "          except FileExistsError:\n",
        "              pass\n",
        "          url = istmd(url)\n",
        "          if url != False:\n",
        "              print('URL {}'.format(url))\n",
        "              cmdC = f'youtube-dl -o \"{OUTPUT_PATH}/%(title)s.%(ext)s\" {url} ' \\\n",
        "                     '--external-downloader aria2c ' \\\n",
        "                     '--external-downloader-args \"-x 16 -s 16 -k 1M\"'\n",
        "              runSh(cmdC, output=True)\n",
        "      else:\n",
        "        print(\"Please input url\")\n",
        "    print(\"All files downloaded\")\n",
        "\n",
        "\n",
        "\n",
        "def istmd(URL):\n",
        "    link = urlparse(URL)\n",
        "\n",
        "    # YandexDisk\n",
        "    if link.netloc == \"yadi.sk\":\n",
        "        API_ENDPOINT = 'https://cloud-api.yandex.net/v1/disk/public/resources/' \\\n",
        "                        '?public_key={}&path=/{}&offset={}'\n",
        "        dry = False\n",
        "\n",
        "        def md5sum(file_path):\n",
        "            md5 = hashlib.md5()\n",
        "            with open(file_path, 'rb') as f:\n",
        "                for chunk in iter(lambda: f.read(128 * md5.block_size), b''):\n",
        "                    md5.update(chunk)\n",
        "            return md5.hexdigest()\n",
        "\n",
        "        def check_and_download_file(target_path, url, size, checksum):\n",
        "            if path.isfile(target_path):\n",
        "                if size == path.getsize(target_path):\n",
        "                    if checksum == md5sum(target_path):\n",
        "                        print('URL {}'.format(url))\n",
        "                        print('skipping correct {}'.format(target_path))\n",
        "                        return\n",
        "            if not dry:\n",
        "                print('URL {}'.format(url))\n",
        "                print('downloading {}'.format(target_path))\n",
        "                #os.system(f'aria2c -x 16 -s 16 -k 1M -d {OUTPUT_PATH} {url}')\n",
        "                os.system(f\"aria2c -x 16 -s 16 -k 1M -d '{OUTPUT_PATH}' '{url}'\")\n",
        "\n",
        "        def download_path(target_path, public_key, source_path, offset=0):\n",
        "            print('getting \"{}\" at offset {}'.format(source_path, offset))\n",
        "            current_path = path.join(target_path, source_path)\n",
        "            pathlib.Path(current_path).mkdir(parents=True, exist_ok=True)\n",
        "            jsn = requests.get(API_ENDPOINT.format(public_key, source_path, offset)).json()\n",
        "\n",
        "            def try_as_file(j):\n",
        "                if 'file' in j:\n",
        "                    file_save_path = path.join(current_path, j['name'])\n",
        "                    check_and_download_file(file_save_path, j['file'], j['size'], j['md5'])\n",
        "                    return True\n",
        "                return False\n",
        "\n",
        "            # first try to treat the actual json as a single file description\n",
        "            if try_as_file(jsn):\n",
        "                return\n",
        "\n",
        "            # otherwise treat it as a directory\n",
        "            emb = jsn['_embedded']\n",
        "            items = emb['items']\n",
        "            for i in items:\n",
        "                # each item can be a file...\n",
        "                if try_as_file(i):\n",
        "                    continue\n",
        "                # ... or a directory\n",
        "                else:\n",
        "                    subdir_path = path.join(source_path, i['name'])\n",
        "                    download_path(target_path, public_key, subdir_path)\n",
        "\n",
        "            # check if the current directory has more items\n",
        "            last = offset + emb['limit']\n",
        "            if last < emb['total']:\n",
        "                download_path(target_path, public_key, source_path, last)\n",
        "\n",
        "        download_path(OUTPUT_PATH, URL, '')\n",
        "        return False\n",
        "\n",
        "    return URL\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "B1CIP_91oMWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <img src=\"https://static.mediafire.com/images/backgrounds/header/mf_logo_full_color.svg\" width=\"150px\">\n",
        "\n",
        "\n",
        "\n",
        "!pip3 install git+https://github.com/Juvenal-Yescas/mediafire-dl\n",
        "import mediafire_dl\n",
        "\n",
        "url = \"\" #@param {type:\"string\"}\n",
        "output = \"\" #@param {type:\"string\"}\n",
        "mediafire_dl.download(url, output, quiet=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WHETLI1r0T1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <h3><b>←</b> ZIP/RAR Extractor\n",
        "!pip install rarfile\n",
        "\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import rarfile\n",
        "\n",
        "file_path = \"\" # @param {type:\"string\"}\n",
        "extraction_directory = \"\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "def unzip(zip_file, extract_to):\n",
        "    print('Extracting ZIP file')\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "\n",
        "def unrar(rar_file, extract_to):\n",
        "    print('Extracting RAR file')\n",
        "    with rarfile.RarFile(rar_file, 'r') as rar_ref:\n",
        "        rar_ref.extractall(extract_to)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   # file_path = 'example.zip'  # Replace with your file path\n",
        "   # extraction_directory = 'extracted_files'\n",
        "\n",
        "    # Create the extraction directory if it doesn't exist\n",
        "    if not os.path.exists(extraction_directory):\n",
        "        os.makedirs(extraction_directory)\n",
        "\n",
        "    # Check the file extension to determine the format\n",
        "    file_extension = os.path.splitext(file_path)[1]\n",
        "\n",
        "    if file_extension.lower() == '.zip':\n",
        "        # Unzip the ZIP file\n",
        "        unzip(file_path, extraction_directory)\n",
        "        print(f\"Successfully unzipped {file_path} to {extraction_directory}\")\n",
        "    elif file_extension.lower() == '.rar':\n",
        "        # Unrar the RAR file\n",
        "        unrar(file_path, extraction_directory)\n",
        "        print(f\"Successfully unrar'd {file_path} to {extraction_directory}\")\n",
        "    else:\n",
        "        print(f\"Unsupported file format: {file_extension}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fQO0EicW7P_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}